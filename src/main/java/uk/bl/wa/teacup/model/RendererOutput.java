/**
 * 
 */
package uk.bl.wa.teacup.model;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

import org.apache.xerces.impl.dv.util.Base64;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.fasterxml.jackson.core.JsonParseException;
import com.fasterxml.jackson.databind.JsonMappingException;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;

/**
 * 
 * Takes the HAR output String generated by our tools and parsers it into the
 * crucial elements.
 * 
 * TODO Handle redirected URLs better?
 * 
 * TODO Add tests.
 * 
 * The parsers can be split into Factories later if we need to in order to
 * support multiple renderers.
 * 
 * @author Andrew Jackson <Andrew.Jackson@bl.uk>
 *
 */
public class RendererOutput {

    private static final Logger LOG = LoggerFactory.getLogger(RendererOutput.class);

    public List<CrawlURL> discoveredURLs = new ArrayList<CrawlURL>();

    public String renderedContent;

    public byte[] renderedImage;

    public RendererOutput(CrawlURL url, String harSource) throws JsonParseException, JsonMappingException, IOException {

        // Parse to emit specific elements of the result:
        ObjectMapper mapper = new ObjectMapper();
        JsonNode root = mapper.readValue(harSource, JsonNode.class);
        // Look for dynamic dependencies, i.e. downloaded resources:
        for (JsonNode node : root.path("log").path("entries")) {
            JsonNode rurl = node.path("request").path("url");
            LOG.info("Got requested url: " + rurl.asText());
            // Mark as embeds:
            CrawlURL nurl = url.toParent();
            nurl.url = rurl.asText();
            nurl.forceFetch = true;
            nurl.parentUrl = url.url;
            nurl.pathFromSeed = url.pathFromSeed + "E";
            nurl.httpVersion = node.path("request").path("httpVersion").asText();
            nurl.method = node.path("request").path("method").asText();
            // Headers:
            for (JsonNode header : node.path("request").path("headers")) {
                nurl.headers.put(header.get("name").asText(), header.get("value").asText());
            }
            // Cookies:
            for (JsonNode cookie : node.path("request").path("cookies")) {
                nurl.cookies.add(cookie.asText());
            }
            // Use "pageref" to capture 'parent' page according to the browser?
            // nurl.headers.put("phantomjs-request-pageref",
            // node.path("pageref").asText());
            // And add to the list:
            discoveredURLs.add(nurl);
        }
        // Look through the pages:
        for (JsonNode node : root.path("log").path("pages")) {
            // Look for known links:
            for (JsonNode map : node.path("map")) {
                JsonNode rurl = map.path("href");
                LOG.info("Got clickable href: " + rurl.asText());
                // Mark as links:
                CrawlURL nurl = url.toParent();
                nurl.url = rurl.asText();
                nurl.parentUrl = url.url;
                nurl.pathFromSeed = url.pathFromSeed + "L";
                discoveredURLs.add(nurl);
            }

            // Extract DOM:
            JsonNode renderedContentB64 = node.path("renderedContent").path("text");
            renderedContent = new String(Base64.decode(renderedContentB64.asText()), "UTF-8");

            // Extract root view image:
            for (JsonNode img : node.path("renderedElements")) {
                String selector = img.path("selector").asText();
                if (":root".equals(selector)) {
                    JsonNode pngB64 = img.path("content");
                    renderedImage = Base64.decode(pngB64.asText());
                }
            }
         }
    }

}
