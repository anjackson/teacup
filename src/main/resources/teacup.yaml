# topology definition
# name to be used when submitting
name: "teacup"

# topology configuration
# this will be passed to the submitter as a map of config options
#
config:
  topology.workers: 2
  topology.message.timeout.secs: 300
  topology.max.spout.pending: 2
  topology.debug: false
  topology.kryo.register: 
  - com.digitalpebble.storm.crawler.Metadata

  topology.metrics.consumer.register: 
  - class: backtype.storm.metric.LoggingMetricsConsumer

  fetcher.server.delay: 1.0
  fetcher.server.min.delay: 0.0
  fetcher.queue.mode: "byHost"
  fetcher.threads.per.queue: 1
  fetcher.threads.number: 10

  partition.url.mode: "byHost"

  # lists the metadata to transfer to the outlinks
  # used by Fetcher for redirections, sitemapparser, etc...
  metadata.transfer:
  - key1
  - key2
  - key3  

  http.agent.name: "Teacup Crawler"
  http.agent.version: "1.0"
  http.agent.description: "a Storm-based crawler"
  http.agent.url: "https://github.com/anjackson/teacup"
  http.agent.email: "anj@anjackson.net"

  http.accept.language: "en-us,en-gb,en;q=0.7,*;q=0.3"
  http.accept: "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
  http.content.limit: 65536
  http.store.responsetime: true
  http.timeout: 10000

  http.robots.403.allow: true

  # should the URLs be removed when a page is marked as noFollow
  robots.noFollow.strict: true

  protocols: "http,https"
  http.protocol.implementation: "com.digitalpebble.storm.crawler.protocol.httpclient.HttpProtocol"
  https.protocol.implementation: "com.digitalpebble.storm.crawler.protocol.httpclient.HttpProtocol"

  parsefilters.config.file: "parsefilters.json"
  urlfilters.config.file: "urlfilters.json"

  # whether the sitemap parser should try to 
  # determine whether a page is a sitemap based
  # on its content if it is missing the K/V in the metadata
  sitemap.sniffContent: false

  # revisit a page daily (value in minutes)
  fetchInterval.default: 1440

  # revisit a page with a fetch error after 2 hours (value in minutes)
  fetchInterval.fetch.error: 120

  # revisit a page with an error every month (value in minutes)
  fetchInterval.error: 44640

  stormcrawler.indexer.class: "com.digitalpebble.storm.crawler.indexing.StdOutIndexer"

  # configuration for the classes extending AbstractIndexerBolt
  # indexer.md.filter: "someKey=aValue"
  indexer.url.fieldname: "url"
  indexer.text.fieldname: "content"
  indexer.canonical.name: "canonical"
  indexer.md.mapping:
  - parse.title=title
  - parse.keywords=keywords
  - description=description
  - canonical=canonical  

# spout definitions
spouts:
  - id: "spout"
    className: "com.digitalpebble.storm.crawler.spout.RandomURLSpout"
    parallelism: 1

# bolt definitions
bolts:
  - id: "partitioner"
    className: "com.digitalpebble.storm.crawler.bolt.URLPartitionerBolt"
    parallelism: 1

  - id: "fetch"
    className: "com.digitalpebble.storm.crawler.bolt.FetcherBolt"
    parallelism: 1

  - id: "sitemap"
    className: "com.digitalpebble.storm.crawler.bolt.SiteMapParserBolt"
    parallelism: 1

  - id: "parse"
    className: "com.digitalpebble.storm.crawler.bolt.JSoupParserBolt"
    parallelism: 1

  - id: "switch"
    className: "com.digitalpebble.storm.crawler.bolt.StatusStreamBolt"
    parallelism: 1

  - id: "index"
    className: "com.digitalpebble.storm.crawler.indexing.StdOutIndexer"
    parallelism: 1

  - id: "status"
    className: "com.digitalpebble.storm.crawler.bolt.PrinterBolt"
    parallelism: 1

# stream definitions
streams:
  - name: "spout --> partitioner"
    from: "spout"
    to:   "partitioner"
    grouping:
      type: LOCAL_OR_SHUFFLE

  - name: "partitioner --> fetch"
    from: "partitioner"
    to:   "fetch"
    grouping:
      type: FIELDS
      args: ["key"]

  - name: "fetch --> sitemap"
    from: "fetch"
    to:   "sitemap"
    grouping:
      type: LOCAL_OR_SHUFFLE

  - name: "sitemap --> parse"
    from: "sitemap"
    to:   "parse"
    grouping:
      type: LOCAL_OR_SHUFFLE

  - name: "parse --> switch"
    from: "parse"
    to:   "switch"
    grouping:
      type: LOCAL_OR_SHUFFLE

  - name: "parse --> index"
    from: "parse"
    to:   "index"
    grouping:
      type: LOCAL_OR_SHUFFLE

  - name: "fetch --> status"
    from: "fetch"
    to:   "status"
    grouping:
      type: LOCAL_OR_SHUFFLE
      streamId: "status"

  - name: "sitemap --> status"
    from: "sitemap"
    to:   "status"
    grouping:
      type: LOCAL_OR_SHUFFLE
      streamId: "status"

  - name: "switch --> status"
    from: "switch"
    to:   "status"
    grouping:
      type: LOCAL_OR_SHUFFLE
      streamId: "status"

  - name: "parse --> status"
    from: "parse"
    to:   "status"
    grouping:
      type: LOCAL_OR_SHUFFLE
      streamId: "status"



